 One of the things I hope you could spend time on is because I know you don't have no chance for a long time you've been thinking hard about education, be some fairly extraordinary things. Just catch us up from the time you started kind of academy to the first few years in several years. How do you feel about the progress that you've made and the impact that you've had? Can you describe that journey a little bit? Yeah, I mean, as you know, a lot of folks know, kind of kind of kind of me started in a somewhat random way back in 2004, cousins needed help with tutoring. I started tutoring remotely. I was an analyst at a hedge fund at the time. I started building tools for them. I saw common pattern. My cousins were having. The reason why they're struggling is especially in math is they had gaps in their knowledge. And so I started making exercises for them to get practice and then I as their tutor could keep track of. That was the first kind of academy. You had nothing to do with videos at the time. Then 2006, a friend suggested that I make videos for my cousins to supplement because I was now we're in his friend and my family that free tutoring was going on. So now I was tutoring 10, 15 cousins every day. I felt like I was explaining least common multiple like every other week. And a friend said, well, want you to make some videos uploaded on the YouTube for your family. They appreciated me in their lives, I think. But they liked a on-demand version that one that they didn't have to feel embarrassed about. If they had a question from, say, arithmetic and they're an algebra now, no shame. They could pause, they could repeat, they could watch it in the middle of the night when they needed help. And it just being on YouTube, it was very discoverable by a lot of other folks. And by 2008, 2009, there were about 50 to 100,000 folks. But to Google and the Gates Foundation's credit by fall of 2010, I'll give a set of initial funding to become a real organization. And you fast forward over the last, that was 2010, so 13, 14 years. We're now over 150 million registered users. Once I saw the traction, once I saw that people were getting value out of the practice and the exercises and the software, that's actually where, especially once we got funding, we're most of our resources went behind. You can learn a little bit by watching a video, but you learn a lot more by getting practice and feedback, et cetera, et cetera. I said, like, I just need to keep scaling this idea. I remember several years ago, Connor Kermans already at scale, right? One of the things that struck me the most was how it seemed to be kids from everywhere. So even in those early days, when I was making things for 10, 15 cousins, but I wrote soft, anyone who's ever worked on software, you always have dreams, well, if it works for these 15, there's no reason why I couldn't one day work for 15 million people, or 150 million, or 1.5 billion people. And I wrote that somewhat grandios mission statement, free world class education. I remember that. And you went anywhere. It was a grandiose idea. You know, my dream is not only can you learn anything, but you can prove what you know, and you can get connected to opportunity. Well, come to this moment. The second thing happened, AI. So talk a little bit about how much, what extent has AI been a game changer here? Or what differences it made to the way you think about learning, teaching, all of this? And also questions of scale. We've been trying to scale what a good tutor would do. A good tutor can see where you are, give you practice that's appropriate for you, not just for the whole class at 30, in which case most kids are lost or bored. A good tutor can motivate you, really focus on you, et cetera. So we were trying to approximate that with videos, exercises, and then give tools to teachers so that they can approximate that, even though they have a 1 to 30 ratio. Separately, I was, as just a tech nerd, I was paying attention to, I've always been intrigued by AI. In fact, in college probably my two big interests were AI in education. In science fiction. In science fiction. Well, that's why I was interested in AI in education. You know, in the late 90s when I was in college, I was like, ah, this is a long way to go before this gets interesting. And I'd even watched some of the gender-devae I as of several years ago and I'm like, oh, this is pretty impressive. But it's ever prone, it'll hallucinate. But last year when we saw what, I guess today, they called the frontier models, the today's frontier models can do. And they went from being able to write things that appear, cogent, but aren't to things that truly are, and that you could actually engage with them, and that they can actually take on personas. And do things that just don't sound pedagogically strong, but are. Then we say, okay, this changes everything. It still has issues. It still can hallucinate. It's still, the large language models are infamously bad at math. But we've felt like if we don't, the rate at which this is improving, if we don't start acting on this now is going to be a lost opportunity. What exactly does it change? It changes the richness of the interaction that you can provide for. Initially, we thought for a student and we still believe that, but then we realized also for a teacher and also for a parent. Essentially, allows you to talk to something. I don't think it's hard to extrapolate from, we launched called Kanmigo on Khan Academy. It's still not of the scale of Kan Academy because there's real costs. I was in this generative AI and all of that. But I think and Kanmigo can already do a lot of cool things, but I think in two or three years, it's going to be able to approximate with the rest of the, I think just a generative AI by itself is kind of interesting, but if you put it with all the other content and the scope and sequence and the curriculum and all of this other stuff we created, I think in two or three years, it's going to be 90% as good as I was with my cousins. Well, I've been one of the things, I mean, one of the critiques that's come up with generative AI and learning is all of a sudden kids are not right essays anymore. They can just get answers. It does their homework for them. Talk a little bit about that critique and also what have you done to try to make this as useful as possible without being a pretzels something to just generate the answers. Yeah, as soon as we saw what this latest generation of models could do, we were excited and then put our teams like, well, I think this could be used for cheating. How do we know about bias here? Oh, every now and then it makes up stuff. It's, and our team was about split right down the middle. Some of them, like, we want nothing to do with this stuff. And the other half of the team was like, we want everything to do with this stuff. You guys have seen this coming, even before us, but I encouraged our team to say, like, look, let's turn them into features. What are those risks? Oh, so what's cheating cheating cheating risk? Okay. So we said, look, we can make what would eventually be called Kanmigo, right, not cheat for you. It'll act as a ethical tutor. Like, when if my cousins called me up in 2004 and said, sal, have this homework problem. Can you do it for me? I'm like, no, but I'll like work. I'll ask you some questions. I'll help you understand it. And we were very quickly able to prompt the AI to not cheat, but help and be socratic. We're afraid of, well, what if a student has a weird conversation with it and parents and teachers don't know about it? Well, the solutions make it transparent to parents and teachers. We already have that relationship in the classroom where we know which students are connected to which teachers, what if we made the teachers aware of those conversations? What if we had a second AI that moderates the conversations? And if anything, it's really shady, we'll actively notify the parents and teachers. What if we could add layers on top of just the core model so that the math can get dramatically better? And every hour we started doing that, it got better. And we weren't, we did a little bit of fine-tune training of the underlying models, but for the most part, it was just layers and techniques to use it better. And then we started realizing that some of the things by leaning in, we could even address, even if we weren't going to let people cheat with the gender AI, things like chatGPT still exist out there. And so people could use that. But we said, well, you know, for too long, writing has been about just the output. But what if it's about the process of getting it there? And we're like, you know, Konmigo or gender AI in general could help you write the essay, not do it for you, but it could be like a writing coach. And then what if it reported back to the teacher, not just your final essay, but also where it how you did it? And the process. As we train and build these models, they're often two additional things that we do. So, you know, the base model is trained when we present it to the world. We gotraelit, right to say, you know, this is out of bounds. You know, this is toxic, this is biased, this is dangerous, this is potentially harmful. The second thing we also do to the base model when we try to apply it in a particular domain is to do some further fine tuning. We also try to do some additional what's now called our alert chef, really first one learning with human feedback. Those are things that we try to do to make these useful and more helpful to people. Talk to me about how you work with those things you do in an educational context. As a specter of gardens are probably different in an education aspect, as a specter of fine shootings a little bit different. But describe how you do that for education. We realize that for general audience, for an 18 plus audience, certain things might be okay, but it's not an Australian education context. Or that maybe it is OK in education context, but if students in a math class and they're working on their Khan Academy and they need to learn how to factor upon no meal, there's attention on, you know, maybe you can go on a little bit of a tangent with them about something, but if the students want, even if it's a good conversation, even if they want to have conversation about the meaning of life, we're working on factoring the polynomial, that's what a good tutor would do. Let's talk about the meaning of life some other time. So we have to think about those types of things. We're even thinking about guardrails of like sometimes, maybe the teacher needs to be able to turn off the AI. The teacher needs to be able to monitor what's going on. We're talking about an 18 plus audience, you can ask anything and get any response within with reasonable guardrails, but here we have to worry a lot about the cheating issue. We worry a lot about the socratic, like what's the socratically correct thing to do? And then as you mentioned, we want to teach everything, but math is almost our core and large language, well, we're not good at math. And so there's just a ton of work that we've been doing. And I'll say one thing that I think, yeah, I don't want to give our secret sauce away to other folks, but I've been surprised how little effort other people have put into just making the experience magical. But these models are amazing, but if you don't put work into that, they can feel a little bit still to a little bit robotic, but they're capable of having real personality. And a lot of folks when they work with Konmigo, they immediately notice this feels different. If you ask Konmigo, if you're watching a video like, why do I have to learn this? Konmigo won't just immediately respond, I say, well, what do you care about? So it's really trying to put some of that magic in that makes it really feel like a human interaction. Well, a lot of what you describe south sounds to me as if it's a way to use this technology to do what a really good teacher or tutor or educator would do. Right, pay attention to how to differentiate, have the right, so credit dialogue that it enables learning and so forth. So I get that, but I'm also curious, are there some things where you think there might actually be some superpowers here where the learning process actually aids in ways that perhaps we can't quite do yet. At least give you one of my early experiences, which was quite surprising and interesting to remember about a year, actually two years ago, I was playing with one of these base large models and playing with a few different kinds of prompts and then doing some prompt engineering. So one of the things I was interesting was trying to prompt that went as follows, explain quantum mechanics to a 12-year-old who understands algebra but hasn't learned physics yet. Right, so I'll try to get a, you know, a teaching biology teaching by taking language or principles from one field, applying to another in a way that's pedagogically interesting. And it was pretty good actually. So to me, those are an example of, I don't know if I would have been able to do that, no that I'm claim to be a good teacher, but other other things that you said, well, this might actually be a superpower that allows us to do things that are difficult for us to do. But I want to be to step back a bit in the following sense. You know, we've seen over history ways of technology that have changed how learning happens and what is considered learning, what's considered an educated experience. I mean, I'm old enough to remember the time when in fact, we are not allowed to bring calculators into class because, you know, you're supposed to do this all the math in your head, right? And until you could do that, you have a good mathematician. We've put perhaps all the time in history as well, remembering the dates and the battles and all these things. Then we also had the next wave when people could actually just Google things, right? So the day homework, you just Google things. So I guess I'm bringing those up to say to get a sense of to what extent do you think this is the same and different than those other technological experiences that in some ways changed how we think about education? I mean, I think it's great now that there are incredibly good mathematicians who still can't do math in their heads. We're comfortable with that. We know that there's a way to be good at math math, so I'm being able to do the arithmetic in your head. Talk a little bit about what you think is the same and different between this and other previous technologies. Yeah, and I'll start because I don't think anyone else defends like traditional ascetication, so I'll do a little bit of it. I won't go all in because I don't think education would be nothing but memorization all of that. But I have always believed that it is useful to have quick access to a lot of information. And even if you're memorizing multiplication tables or having access to dates, over time you start drawing connections between them. You start seeing patterns. So it is good to know the dates of Pearl Harbor, the dates of World War One, or it just gives you context. And then it allows you to be a better user of tools. You're more likely to find what you're looking for on Google. Right. If you have some context already, then if you're just searching for one. So you need to learn the, yes, it's where to train your brain almost. Exactly. And you'll form connections. I think generative AI to some degree raises the stakes. You can't manage junior software engineers unless you are a solid software architect. You can't, you can't edit a newspaper, unless you could be a staff writer. And so we're entering a world where AI can be the entry level software engineer. It can be the staff writer, but the students need to elevate. If they want to leverage them. Yeah, but let me press you on this a little bit in the following sense. I mean, I think probably I think we've fair to say most of us, uh, often will use artifacts as a way to assess learning intelligence, comprehension and all of that. And one of the artifacts we've all relied on for a very long time in recent history is the essay, right? Because it's supposed to show rational thinking, evaluation, considering this considering that thinking away through a problem and reaching a conclusion, right? That's been one of the artifacts that does that. Do you still think that's going to be a useful artifact in this new world with these technology? What I'm excited about is, I think the, the, the, the universe of artifacts that we can now lean on are going to get much richer and much better. The essay was one, okay, you can make a student go work on that for a week and then a professor or teaching assistant could read it, you know, over like 10 minutes and have a sense of things. There are always what we've perceived richer artifacts, but they were expensive or exams for a PhD defense. The job interview, right, a performance task, a simulation, but that's super expensive to do at scale until maybe now. Uh, so I actually think that you could have AI's give you an interview, AI's that are able to walk you through a simulation and doesn't even have to be text-based. It could even be visual-based. It could be on video. And then that'll capture things that the essay could never have, how well you can speak, how well you can make eye contact, how personable you are. And I know there's a lot of fear to about AI's assessing you and this being used in high stakes things and we have to do all of that with care, but I always say nothing is ever going to be perfect, but you just have to compare it to the status quo. And so an AI that you can audit that you can run it a million times and see how it performs with different cases and things like that that you could put guardrails on so it performs reasonably consistently. It's probably better. I mean, right now, a lot of human hiring managers, we all have our biases. They have very limited time. You get thousands of resumes. You're hiring managers in about a how hard they try. I mean, it's just human. Thousands of resumes are contents of thousands and you're just, you have probably three four seconds to look at each of them, right? They're going to index on certain things. It's certainly not going to be able to give everyone the benefit of the doubt. And AI could and you're able to audit it. You could use AI to construct resumes that are from different ethnicities, different backgrounds, etc. But otherwise equivalent and then see how another AI performs it. And you know, even you mentioned essay, even the resume as an artifact is pretty archaic because it was meant as this very lightweight signaling thing. Now you could have the hiring managers AI agents have hours long conversation, the equivalent of an hours long conversation with your agent and say you were good fit. But there's a tension here, right? That's fun to try to just what I sense is a tension and we think about this all the time, which is yes, on the one hand, you can imagine an AI system that you, you know, actually does better than either the biases, that we might have as individuals, the humans are so for them, that may be a good thing. At the same time, you also worry about these systems having bias within them. And you know, and the change, of course, when you have bias in AI systems, it's then applied at scale. As opposed to bias in an individual, it may just be constrained to that individual. But be that it's made. There's a tension here. So how do you think we should be thinking about navigating this tension? Because I can see the benefits of using the systems to do the kinds of things that are probably better than what would otherwise happen. But I could also see the the other side of that, where this concerns about the the risks. Right now, I'm actually pretty optimistic. You know, I obviously started kind of going to be the not for profit, because I think market for forces have historically not served the education industry well. But I will say that, so far, I actually think market forces in Genre DeVaire are actually pushing people in the right direction. As you know, very well, whether it's barred, whether it's chat, GPT, it is out there. And you have tens of millions or hundreds of millions of people hitting it. Some people are using it on just everyday basis. But a lot of people are doing kind of what you would call red hat testing. Right? People are looking to do that. And so there's a natural mechanism for essentially the world to audit what's going on. And for companies like Google and Microsoft and OpenAI to be very wary and to put the guardrails. And I think it is a very different dynamic than what we saw with, let's say, social media. Right? With social media, you had a previous generation. I mean, they still exist. These AIs that their objective function is keep people watching eventually watch the ads. And, you know, no one programmed the AIs to do this. But they kind of learned that the ways to do that seem to be reinforced people's existing biases. Give them potentially triggering information. Maybe even made up triggering information. And the market forces didn't push back really heavily on that. Because there was plausible deniability. There was like, look, we just have a platform here. People are posting here. It's a free speech, it's a separate setter, et cetera. And by the way, those things were driving ad revenue. And they were doing all of those things. But I think, I think here we have a different dynamic because the companies to some degree the AI is a representative of those companies. You have so many people who are looking to do gotchas on the AI. So the companies themselves are also doing all of this testing. But, and I always compare things to what the status quo would be. The status quo, like, thing about education. Right now, you have 40, 50 million American kids in millions of classrooms every day. And many of those teachers are really great at not showing bias. But some of them aren't. They have their biases. And it's very hard to audit that at scale. But here you actually will be able to audit it. But once again, whether it's a commigo or whether it's barred or chat GPT or the fact that it's so out there, so many people can hit it and expose any biases it'll have. And some biases will be exposed. But I think it's going to over time get much less biased than your average human being. So you and I haven't talked since you did your most recent TED talk. And I watched it one of the things you say in it, I think, I want quite correctly. So AI may actually save humanity or something to that effect. That's a pretty bold edition statement. What did you mean by that? I think good actors using AI well are going to be able to help educate us, help have better health care. I actually think help bring us to a more moderate point of view. I mean just even the notion of a secratic dialogue, right? Like how many news outlets say, well, why do you think that's true? Like, let's let's scrutinize what your current opinions are. They don't do that. They tend to just feed feed into that. So I am hopeful that if as long as the people who are using it for good, have more energy by the people who are using it for bad, there's definitely things to worry about. There's totalitarian governments using it to surveil people. Fraud is going to go through the roof where you're going to get a call from someone who sounds like your kid or your relative. I need money. So I worry about all that. As long as the people who are forces of good have more energy and more creativity, I think we're going to be in a, and we have real sought things to solve. We need to educate people more. We need to solve climate change. We need to depolarize ourselves and, you know, if you yourself, it's a thing that we're trying to think about, which is on the one hand, how do we make sure we apply this to the most useful things that could benefit education learning, how to climate all these things that we, I think we all want, but at the same time, be mindful of the challenges and the risks. Well, let's do a thought experiment. Let's suppose it's now 2050, the year 2050, and we're looking back and the world is journey happy. Yeah, I happen. We think this is such a terrific thing. So the question is what happened? What did we get right for us to have that view? What problem did we solve? What amazing things happened? What happened? Well, I guess it's a way to think about how do we get this right? I'd like to think, you know, before generative AI is to give the example that at one time things like algebra or even literacy, we're considered a very like only a very small 10, 20% of the population. Now we assume, you know, gentlemen's call is exactly right. And now in wealthy countries, 95% plus 99% plus the population are literate. I am, but today we think of quantum physics or, starting the next Google as something that only a small sliver of humanity can actually do. In 50 years, I hope we're saying, could you imagine we once thought that now everyone knows quantum physics. Everyone is an entrepreneur. Everyone knows how to put the pieces together. Let me add a few other things I think about as well, which is, I hope that when we look back and this is getting all the amazing future you just described, we've also solved a few critical things. I actually think we, I hope will have solved the question about how do we get every to participate in this. I suppose to just a few, because there's one thing to create this huge bounty, but if not everybody can be part of that, I think that's problematic. I also hope that we would have found kind of rigorous way to solve for these issues like safety, things like some of the performance issues that we've got. And I also hope that we would have figured out some of the right governance mechanisms. I mean, I think any time you have a powerful technology, I think it's important to to govern it well, both to so that you can actually stop all the things you don't want to have happened, but also enable all the things that you actually want to have happened. So I think hopefully we'll have figured it out. And I also hope that there'll be some, I don't know, standards is probably too strong a word, but some way to think about this everywhere, not just in one country or another country, but just globally. I think we have some work to do. I agree. We gotta do it. Well, thank you. Thanks for making the time. Thanks for having me, James.